#Aim: To predict percentage of voting find relationship between percentage of voting and other predictors
#Parameter to be analyzed: Percentage of Voting
#No of dataset: 1 dataset
#Study design: paired
#Distribution of data: non-normal

#after looking at the results, we can see that poverty's p-value is less than 0.05 hence it is statistically insignificant.
#This means that we can reject the null hypothesis which says that There is no statistical difference 
#from p-values, we can deduce that poverty does have a significant effect on the voting percent of President CLinton
#std error: it is the standard deviation of the sampling distribution of the estimate of the coefficient under the standard regression assumptions.  Such standard deviations are called standard errors of the corresponding quantity
#estimate of the variance of the strength of the effect, or the strength of the relationship between each causal variable and the predicted variable. If it's high, then the effect size will have to be stronger for us to be able to be sure that it's a real effect, and not just an artefact of randomness.
#t-value is the value of the t-statistic for testing whether the corresponding regression coefficient is different from zero
#p-value
#residual standard error: it represent the standard deviation of the residuals. Its a measure of how close the fit is to the points
#multiple r-squared: also called coefficient of determination it is the proportion of the variance in the data that's explained by the model. The more the variables one add, the larger this value will be
#Adjusted one: reduces that to account for the number of variables in the model
#f-statistic tells whether the regression as a whole is performing better than the random. its seeing whether my model fits better than I'd expect if all my set of predictors had no relationship with the response.


#lm model interpretation: Coefficients Estimate: One unit increase in X, one unit increase in Y
#2. Coefficient Std Error: measures how precisely the model estimates the coefficients unknown value.low value the better
#3.Higher the t-value, we can reject the p-value
#4. asterisk mark define significance of value, lower the value high is the significance
#5. Residual stnadard error: how well our model is going to predict the data on average
#6. Multiple rsquared: high value are better % of variation in the response variable, used to calculate how well the model is doing th explain the things
#7. adjusted Rsquared: adjusted value in which we does not take all variables, only significant variable are considered in adjusted R squared
#8. F statistic: This is showing relationship between predictor and response, higher the value will give more reasons to reject null hypothesis, its significant of overall model not any specific parameter
#9. p-value of F0statistic: Overall p value on the basis of F-statistic, normally p value less than 0.05 indicate that overall model is significant

library(caret)
data <- read.csv("C:/Users/Madhura Snehal/Desktop/Madhura/Fall 2018/Adv Stats/Project/ClintonData.csv")
head(data)
colnames(data)
plot(data)
#From the histogram, we can observe that overall president Bill Clinton received votes between 30-40%
hist(data$voting)
boxplot(data$voting)
model <- lm(data$voting ~ (Median.Age+Percent.in.Poverty+Percent.Veterans+Percent.Female+Population.Density+Percent.in.Nursing.Homes), data=data)
summary(model)
poly_model <- lm(data$voting ~ polym(Percent.in.Poverty, degree=3, raw=TRUE),data=data)
summary(poly_model)

#loess model
lmodel3 <- loess(voting~Percent.in.Poverty,span=.2, data = data)
#Rsquare value
print(cor(data$voting, predict(lmodel3))^2)
## [1] 0.706345
#RMSE value
print(sqrt(mean((data$voting-lmodel3$fitted)^2)))
## [1] 328.228
plot(data$voting,data$Percent.in.Poverty,xaxt="n",bty="n",pch=16,cex=.5,type="o",las=1,
     ylab="Voting",xlab="poverty")
axis(1,10:90,las=3,cex.axis=.95)
lines(predict(lmodel3), x=data$voting, col="gold")
#Calculating AIC values
data.frame(model=paste("P",1:3,sep=""),rbind(extractAIC(model1),
                                             extractAIC(model2),
                                             extractAIC(model3)))
                                             

#graph indicates that crime rate is high between the age 30-35. 
t1 <- cor(data$Median.Age, data$Crime.Index)
as.matrix(t1)
plot(data$Median.Age, data$Crime.Index)
#As age increases, earning capacity increases and savings
t2 <- cor(data$Median.Age, data$Mean_Savings)
as.matrix(t2)
plot(data$Median.Age, data$Mean_Savings)
#As age increases, per capita increases
t3 <- cor(data$Median.Age, data$PerCapita.Income)
as.matrix(t3)
plot(data$Median.Age, data$PerCapita.Income)
#cannot use t.tests because variables are highly independent.

#Shapiro test - tests whether the sample is normally distributed or not
shapiro.test(data$voting)

#null hypothesis: Voting and Crime are independent
#Alternate: Voting and crime are not independent
cor.test(data$voting, data$Crime.Index, method='pearson')
plot(data$Crime.Index, data$voting)
#Conclude that crime index and voting independent
cor.test(data$voting, data$Median.Age)
plot(data$Median.Age, data$voting)
#the results show that the age and voting are dependent. From the plot we can see that the age group of 31-36 were not in much favor of President Bill Clinton

#predictors
model1 <- aov(data$voting ~ (Median.Age+Percent.in.Poverty+Percent.Veterans+Percent.Female+Population.Density+Percent.in.Nursing.Homes), data=data)
summary(model1)
model2 <- lm(data$voting ~ (Median.Age+Percent.in.Poverty+Percent.Veterans+Percent.Female), data=data)
summary(model2)
model3 <- lm(data$voting ~ (Median.Age+Percent.in.Poverty+Percent.Female+Crime.Index), data=data)
summary(model3)
model4 <- lm(data$voting ~ (Median.Age+Percent.in.Poverty+Percent.Female+Population.Density+Percent.in.Nursing.Homes+Crime.Index), data=data)
summary(model4)

library(faraway)
library(BayesFactor)

anova(model3, model1)
#r <- regressionBF(data$voting ~ Median.Age+Percent.in.Poverty+Percent.Veterans+Percent.Female+Population.Density+Percent.in.Nursing.Homes, data=data)
             
